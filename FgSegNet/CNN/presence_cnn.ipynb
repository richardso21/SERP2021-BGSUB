{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T20:51:18.097933Z",
     "iopub.status.busy": "2020-10-22T20:51:18.097415Z",
     "iopub.status.idle": "2020-10-22T20:51:18.106289Z",
     "shell.execute_reply": "2020-10-22T20:51:18.105071Z",
     "shell.execute_reply.started": "2020-10-22T20:51:18.097877Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py, os, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " - Generate a specific model for each scene\n",
    "     - Each location: 1600 images w/o presence, 800 imags w/ presence\n",
    " - Create Dataloader\n",
    "     - 80-20 split for training/testing (validation?)\n",
    "     - Each img (input size): 1024 x 720 px\n",
    " - Model Architecture\n",
    "     - Modified VGG16?\n",
    "     - Custom CNN architecture?\n",
    "     - Concatenate pixel values and put in logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Base/Helpers/Train & Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T20:47:45.134946Z",
     "iopub.status.busy": "2020-10-22T20:47:45.134199Z",
     "iopub.status.idle": "2020-10-22T20:47:45.144540Z",
     "shell.execute_reply": "2020-10-22T20:47:45.143238Z",
     "shell.execute_reply.started": "2020-10-22T20:47:45.134888Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outs, labels):\n",
    "    res = {}\n",
    "    # check accuracy for 3 different thresholds\n",
    "    for th in [.50, .75, .80]:\n",
    "        outs_th = outs >= th\n",
    "        # append onto result dictionary to be returned to function that called `accuracy()`\n",
    "        res[th] = torch.tensor(torch.sum(outs_th == labels).item() / len(outs))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T20:48:31.360897Z",
     "iopub.status.busy": "2020-10-22T20:48:31.360342Z",
     "iopub.status.idle": "2020-10-22T20:48:31.381877Z",
     "shell.execute_reply": "2020-10-22T20:48:31.380624Z",
     "shell.execute_reply.started": "2020-10-22T20:48:31.360837Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelBase(nn.Module):\n",
    "#     training step\n",
    "    def train_step(self, batch):\n",
    "        xb, labels = batch\n",
    "        outs = self(xb)\n",
    "        loss = F.binary_cross_entropy(outs, labels)\n",
    "        return loss\n",
    "#     validation step\n",
    "    def val_step(self, batch):\n",
    "        xb, labels = batch\n",
    "        outs = self(xb)\n",
    "        loss = F.binary_cross_entropy(outs, labels)\n",
    "        acc = accuracy(outs, labels)\n",
    "        return {'loss': loss.detach(), 'acc': acc}\n",
    "#     validation epoch (avg accuracies and losses)\n",
    "    def val_epoch_end(self, outputs):\n",
    "        batch_loss = [x['loss'] for x in outputs]\n",
    "        avg_loss = torch.stack(batch_loss).mean()\n",
    "        batch_acc50 = [x['acc'][.50] for x in outputs]\n",
    "        batch_acc75 = [x['acc'][.75] for x in outputs]\n",
    "        batch_acc80 = [x['acc'][.80] for x in outputs]\n",
    "        avg_acc50 = torch.stack(batch_acc50).mean()\n",
    "        avg_acc75 = torch.stack(batch_acc75).mean()\n",
    "        avg_acc80 = torch.stack(batch_acc80).mean()\n",
    "        return {'avg_loss': avg_loss, 'avg_acc': [avg_acc50, avg_acc75, avg_acc80]}\n",
    "#     print everything important\n",
    "    def epoch_end(self, epoch, avgs, test=False):\n",
    "        s = 'test' if test else 'val'\n",
    "        print(f'EPOCH {epoch + 1:<10} | {s}_loss:{avgs[\"avg_loss\"]:.3f}, {s}_acc (threshold): (.50){avgs[\"avg_acc\"][0]:.3f}, (.75){avgs[\"avg_acc\"][1]:.3f}, (.80){avgs[\"avg_acc\"][2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T20:54:25.623129Z",
     "iopub.status.busy": "2020-10-22T20:54:25.622573Z",
     "iopub.status.idle": "2020-10-22T20:54:25.639573Z",
     "shell.execute_reply": "2020-10-22T20:54:25.638325Z",
     "shell.execute_reply.started": "2020-10-22T20:54:25.623069Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_dl):\n",
    "    # eval mode\n",
    "    model.eval()\n",
    "    outputs = [model.val_step(batch) for batch in val_dl]\n",
    "    return model.val_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def fit(epochs, lr, model, train_dl, val_dl, opt_func=torch.optim.Adam):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    # define optimizer\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    # for each epoch...\n",
    "    for epoch in range(epochs):\n",
    "        # training mode\n",
    "        model.train()\n",
    "        # (training) for each batch in train_dl...\n",
    "        for batch in tqdm(train_dl):\n",
    "            # pass thru model\n",
    "            loss = model.train_step(batch)\n",
    "            # perform gradient descent\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # validation\n",
    "        res = evaluate(model, val_dl)\n",
    "        # print everything useful\n",
    "        model.epoch_end(epoch, res, test=False)\n",
    "        # append to history\n",
    "        history.append(res)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T21:15:38.837628Z",
     "iopub.status.busy": "2020-10-22T21:15:38.837037Z",
     "iopub.status.idle": "2020-10-22T21:15:38.857095Z",
     "shell.execute_reply": "2020-10-22T21:15:38.855840Z",
     "shell.execute_reply.started": "2020-10-22T21:15:38.837559Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGG16_PT(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         pretrained VGG16 model w/ batch norm\n",
    "        self.network = torchvision.models.vgg16_bn(pretrained=True)\n",
    "#         change first layer to accept only 1 dimension of color (b/w)\n",
    "        self.network.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         change last fc layer to output one value\n",
    "        self.network.classifier[6] = nn.Linear(4096, 1, bias=True)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = network(xb)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T21:25:43.894112Z",
     "iopub.status.busy": "2020-10-22T21:25:43.893459Z",
     "iopub.status.idle": "2020-10-22T21:25:43.908869Z",
     "shell.execute_reply": "2020-10-22T21:25:43.907534Z",
     "shell.execute_reply.started": "2020-10-22T21:25:43.894030Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGG11_PT(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         pretrained VGG16 model w/ batch norm\n",
    "        self.network = torchvision.models.vgg11_bn(pretrained=True)\n",
    "#         change first layer to accept only 1 dimension of color (b/w)\n",
    "        self.network.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         change last fc layer to output one value\n",
    "        self.network.classifier[6] = nn.Linear(4096, 1, bias=True)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = network(xb)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Custom_NPT(ModelBase):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()                                       # 1 x 1024 x 720\n",
    "# #         custom-defined model w/o pretrained weights\n",
    "#         self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)   # 8 x 1024 x 720\n",
    "#         self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)  # 16 x 1024 x 720\n",
    "#         self.pool1 = nn.MaxPool2d(2)                             # 16 x 512 x 360\n",
    "#         self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # 32 x 512 x 360\n",
    "#         self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding=1) # 32 x 512 x 360\n",
    "#         self.pool2 = nn.MaxPool2d(2)                             # 32 x 256 x 180\n",
    "#         self.conv5 = nn.Conv2d(32, 16, kernel_size=3, padding=1) # 16 x 256 x 180\n",
    "#         self.pool3 = nn.MaxPool2d(2)                             # 8 x 256 x 180\n",
    "#         self.fc1 = nn.Linear(8*256*180, 4096)\n",
    "#         self.fc2 = nn.Linear(4096, 512)\n",
    "#         self.fc3 = nn.Linear(512, 1)\n",
    "        \n",
    "#     def forward(self, xb):\n",
    "#         out = F.relu(self.conv1(xb))\n",
    "#         out = F.relu(self.conv2(out))\n",
    "#         out = self.pool1(out)\n",
    "#         out = F.relu(self.conv3(out))\n",
    "#         out = F.relu(self.conv4(out))\n",
    "#         out = self.pool2(out)\n",
    "#         out = F.relu(self.conv5(out))\n",
    "#         out = self.pool3(out)\n",
    "        \n",
    "#         out = torch.flatten(out, 1)\n",
    "#         out = F.relu(self.fc1(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T21:45:08.704997Z",
     "iopub.status.busy": "2020-10-22T21:45:08.704424Z",
     "iopub.status.idle": "2020-10-22T21:45:08.717848Z",
     "shell.execute_reply": "2020-10-22T21:45:08.716551Z",
     "shell.execute_reply.started": "2020-10-22T21:45:08.704934Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGG16_NPT(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         pretrained VGG16 model w/ batch norm\n",
    "        self.network = torchvision.models.vgg16_bn(pretrained=False)\n",
    "#         change first layer to accept only 1 dimension of color (b/w)\n",
    "        self.network.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         change last fc layer to output one value\n",
    "        self.network.classifier[6] = nn.Linear(4096, 1, bias=True)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = network(xb)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
